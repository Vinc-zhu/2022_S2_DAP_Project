---
title: "DAP_Project"
author: "Jinfeng Zhu"
date: "2022-08-15"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Installing libraries
# install.packages("naniar")
library(tidyverse)
library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)

library(janitor) # to clean column names 
library(psych)   # for the describe function

library("stringr") # to add leading zeros
library(naniar) # to check missing values
```

# 1. Exploratory Data Analysis

## 1.1 Import Data

```{r import data, include=FALSE}
data_death      <- read_csv("Data/death.csv")
data_health_ins <- read_csv("Data/healthinsurance.csv")
data_incidence  <- read_csv("Data/incidence.csv")
data_income     <- read_csv("Data/income.csv")
data_population <- read_csv("Data/population.csv")
data_poverty    <- read_csv("Data/poverty.csv")
```

## EDA Framework

## 1.2 Data Exploration

```{r view data}
head(data_death)
head(data_health_ins)
head(data_incidence)
head(data_income)
head(data_population)
head(data_poverty)
```

### 1.2.1 Convert Data Type

```{r}
# Convert the type from character to numeric
# data_death$"Age-Adjusted Death Rate" <- as.double("Age-Adjusted Death Rate")
# data_death$"Average Deaths per Year" <- as.double("Average Deaths per Year")
# 
# data_incidence$"Age-Adjusted Incidence Rate - cases per 100,000" <- as.double("Age-Adjusted Incidence Rate - cases per 100,000")
# data_incidence$"Average Annual Count" <- as.double("Average Annual Count")

data_death <- data_death %>%
  mutate(`Age-Adjusted Death Rate`=as.double(`Age-Adjusted Death Rate`)) %>%
  mutate(`Average Deaths per Year`=as.double(`Average Deaths per Year`))

data_incidence <- data_incidence %>%
  mutate(`Age-Adjusted Incidence Rate - cases per 100,000`=as.double(`Age-Adjusted Incidence Rate - cases per 100,000`)) %>%
  mutate(`Average Annual Count`=as.double(`Average Annual Count`))

#write_excel_csv(data_death, "test_vinc.csv", col_names = TRUE)
```

### 1.2.2 Reshaping Data into Tidy Form

Data will be in tidy form if it has the following 3 properties: 1. Each
variable forms a column 2. Each observation forms a row 3. Each type of
observational unit (e.g. persons, schools, counties) forms a table
Sometimes data in tidy form may also be known as data in long form.

## 1.3 Assess Data Quality

### 1.3.1 Summarise Data

```{r clean header names}
data_death_clean      <- clean_names(data_death)
data_health_ins_clean <- clean_names(data_health_ins)
data_incidence_clean  <- clean_names(data_incidence)
data_income_clean     <- clean_names(data_income)
data_population_clean <- clean_names(data_population)
data_poverty_clean    <- clean_names(data_poverty)

names(data_death_clean)
names(data_health_ins_clean)
names(data_incidence_clean)
names(data_income_clean)       
names(data_population_clean)  
names(data_poverty_clean)

```

### 1.3.2 Visualise and Analyse Patterns in Data

## 1.4 Manipulate and Cleanse the Data

### 1.4.1 Clean FIPS

```{r FIPS}
# Make FIPS a 5-digit code 
# For death and incidence data, most of the FIPS codes are 5-digits but if they are 4-digits, you will need to add a 0 in front. 
data_death_clean_fips <- data_death_clean %>% 
  mutate(fips_clean = str_pad(data_death_clean$fips, width = 5, pad = "0"))

data_incidence_clean_fips <- data_incidence_clean %>% 
  mutate(fips_clean = str_pad(data_incidence_clean$fips, width = 5, pad = "0"))

# For poverty, health insurance, income and population data, you will need to combine State FIPS and County FIPS to get the 5-digit code.
data_health_ins_clean_fips <- data_health_ins_clean %>% 
  mutate(state_fips_clean  = str_pad(data_health_ins_clean$state_fips, width = 2, pad = "0")) %>% 
  mutate(county_fips_clean = str_pad(data_health_ins_clean$county_fips, width = 3, pad = "0")) %>% 
  mutate(fips_clean = paste(state_fips_clean, county_fips_clean, sep=""))

data_income_clean_fips <- data_income_clean %>% 
  mutate(state_fips_clean  = str_pad(data_income_clean$state_fips, width = 2, pad = "0")) %>% 
  mutate(county_fips_clean = str_pad(data_income_clean$county_fips, width = 3, pad = "0")) %>% 
  mutate(fips_clean = paste(state_fips_clean, county_fips_clean, sep=""))

data_population_clean_fips <- data_population_clean %>% 
  mutate(state_fips_clean  = str_pad(data_population_clean$state, width = 2, pad = "0")) %>% 
  mutate(county_fips_clean = str_pad(data_population_clean$county, width = 3, pad = "0")) %>% 
  mutate(fips_clean = paste(state_fips_clean, county_fips_clean, sep=""))

data_poverty_clean_fips <- data_poverty_clean %>% 
  mutate(state_fips_clean  = str_pad(data_poverty_clean$state_fips, width = 2, pad = "0")) %>% 
  mutate(county_fips_clean = str_pad(data_poverty_clean$county_fips, width = 3, pad = "0")) %>% 
  mutate(fips_clean = paste(state_fips_clean, county_fips_clean, sep=""))


# Check in EXCEL: 
# write_excel_csv(data_population_clean_fips, "population_clean_fips.csv", col_names = TRUE)

```

### 1.4.2 Check Duplicate FIPS

```{r check FIPS}
dim(data_death_clean_fips)[1] == length(unique(data_death_clean_fips$fips_clean)) # No duplicates
dim(data_incidence_clean_fips)[1] == length(unique(data_incidence_clean_fips$fips_clean)) # No duplicates
dim(data_health_ins_clean_fips)[1] == length(unique(data_health_ins_clean_fips$fips_clean)) # No duplicates
dim(data_income_clean_fips)[1] == length(unique(data_income_clean_fips$fips_clean)) # No duplicates
dim(data_population_clean_fips)[1] == length(unique(data_population_clean_fips$fips_clean)) # No duplicates
dim(data_poverty_clean_fips)[1] == length(unique(data_poverty_clean_fips$fips_clean)) # No duplicates 
```

### 1.4.3 Expert Opinion

```{r}
# For Incidence dataset, expert opinion suggests suppressed cells of * for Recent Trend is likely to be stable.
# table(data_incidence_clean_fips$recent_trend)

data_incidence_clean_fips_expert <- data_incidence_clean_fips %>% mutate(recent_trend, recent_trend = ifelse(age_adjusted_incidence_rate_cases_per_100_000 == "*", "stable", recent_trend))

table(data_incidence_clean_fips_expert$recent_trend)


# Apply Dummy Encoding for categorical variable "recent_trend"
data_incidence_clean_fips_expert_encoding <- data_incidence_clean_fips_expert %>%
  mutate(trend_falling = ifelse(recent_trend == "falling", 1, 0)) %>%
  mutate(trend_rising  = ifelse(recent_trend == "rising", 1, 0))

table(data_incidence_clean_fips_expert_encoding$trend_falling)
table(data_incidence_clean_fips_expert_encoding$trend_rising)

```
### 1.4.4 Imbalanced Data (maybe for data_all)



## 1.5 Join Datasets

```{r include=FALSE}
# Step 1
dim(data_death_clean_fips)
dim(data_incidence_clean_fips_expert_encoding)
names(data_incidence_clean_fips_expert_encoding)

# Remove columns that are already contained in the left-hand data
data_incidence_clean_fips_for_join <- data_incidence_clean_fips_expert_encoding %>% 
  select(c(3:6))

# Left Join - death / incidence
data1 <- left_join(data_death_clean_fips, data_incidence_clean_fips_for_join, by="fips_clean")
names(data1)

# Step 2
dim(data_health_ins_clean_fips)
names(data_health_ins_clean_fips)

# Remove columns that are already contained in the left-hand data
data_health_ins_clean_fips_for_join <- data_health_ins_clean_fips %>% 
  select(c(1, 5:61,64))

# Left Join - death / incidence / health
data2 <- left_join(data1, data_health_ins_clean_fips_for_join, by="fips_clean")
names(data2)

# Step 3
dim(data_income_clean_fips)
names(data_income_clean_fips)

# Remove columns that are already contained in the left-hand data
data_income_clean_fips_for_join <- data_income_clean_fips %>% 
  select(c(5:14,17))

# Left Join - death / incidence / health / income
data3 <- left_join(data2, data_income_clean_fips_for_join, by="fips_clean")
names(data3)

# Step 4
dim(data_population_clean_fips)
names(data_population_clean_fips)

# Remove columns that are already contained in the left-hand data
data_population_clean_fips_for_join <- data_population_clean_fips %>% 
  select(c(5,8))

# Left Join - death / incidence / health / income / population
data4 <- left_join(data3, data_population_clean_fips_for_join, by="fips_clean")
names(data4)

# Step 5
dim(data_poverty_clean_fips)
names(data_poverty_clean_fips)

# Remove columns that are already contained in the left-hand data
data_poverty_clean_fips_for_join <- data_poverty_clean_fips %>% 
  select(c(5:63,66))

# Left Join - death / incidence / health / income / population / poverty
data_all <- left_join(data4, data_poverty_clean_fips_for_join, by="fips_clean")

glimpse(data_all)

# Check in EXCEL: 
write_excel_csv(data_all, "data_all.csv", col_names = TRUE)

```

## 1.6 Check Missing Values

-   are those that have been suppressed to ensure confidentiality
missing at random: omit it
missing for a specific group: impute

```{r}
# Replace all suppressed value "*" to "NA"
data_all_with_NA <- data_all %>% mutate(across(everything(), function(x){ifelse(x == "*" | x == ".", NA, x)}))
glimpse(data_all_with_NA)
  
miss_var_summary(data_all)
miss_var_summary(data_all_with_NA)
```

## 1.7 Visualising

```{r}
# Take a glance at stroke mortality rate by state
summary_data_all_state <- data_all %>% group_by(state) %>% summarize(death_rate = mean(age_adjusted_death_rate, na.rm=TRUE))
summary_data_all_state 

summary_data_all_state %>% ggplot(aes(state, death_rate)) +
  geom_col()

#==========Example=========#
# exposuretotal <- summary_veh_brand %>% select(veh_brand, exposuretot)
# summary_veh_brand_area <- motor_data %>% group_by(veh_brand, area) %>% summarise(exposure=sum(exposure), claim_num = sum(claim_nb))
# 
# summary_veh_brand_area_total <- left_join(summary_veh_brand_area,summary_veh_brand, by="veh_brand") %>%
#   mutate(incr_freq = claim_num/exposuretot, rel_freq = incr_freq/frequency)
# 
# summary_veh_brand_area_total
# #write_excel_csv(summary_veh_brand_area_total, "Test_Vinc.csv", col_names = TRUE)
# 
# summary_veh_brand_area_total %>% ggplot(aes(veh_brand, rel_freq, fill=area)) +
#   geom_bar(stat = 'identity') #stat identity allows you to make to a y value for bar
#==========================#


# data_all %>% ggplot(aes(state, age_adjusted_death_rate), ) + 
#   geom_boxplot()
#   theme(legend.position="none" #不需要图例
#         # axis.text.x=element_text(colour="black",family="Times",size=14), #设置x轴刻度标签的字体属性
#         # axis.text.y=element_text(family="Times",size=14,face="plain"), #设置x轴刻度标签的字体属性
#         # axis.title.y=element_text(family="Times",size = 14,face="plain"), #设置y轴的标题的字体属性
#         # axis.title.x=element_text(family="Times",size = 14,face="plain"), #设置x轴的标题的字体属性
#         # plot.title = element_text(family="Times",size=15,face="bold",hjust = 0.5), #设置总标题的字体属性
#         # panel.grid.major = element_blank(), #不显示网格线
#         # panel.grid.minor = element_blank()
#         )
#   + scale_y_continuous(breaks = NULL)

```

## 1.X Refine questions/generate new questions (optional)

EDA should not be viewed as just conducting the above framework as a
series of ordered steps. This is far too simplistic as EDA typically
involves multiple rounds of each step. For example, visualisations could
give you new ideas for summaries you would be interested in and perhaps
patterns you want to analyse, which could lead to more manipulations to
the data and visualisations.

### Internal Checks

# Correlation

```{r}
describe(data_poverty)
```

Exploratory data analysis

Objectives: •Suggest hypotheses •Assess assumptions made •Support
selection of appropriate models •Provide basis for further data
collection

FrameworK: 1. Assess the data quality

# 提取各个模型的诊断信息

by_country %\>% summarise(glance(model))
