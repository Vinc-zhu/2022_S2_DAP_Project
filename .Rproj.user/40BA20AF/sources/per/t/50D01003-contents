---
title: "DAP_Project"
author: "Jinfeng Zhu"
date: "2022-08-15"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Installing libraries
# install.packages("simputation")
library(tidyverse)
library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(ggthemes)
  # theme_economist()
  # theme_fivethirtyeight()
  # theme_bw()
library("corrplot")

library(janitor) # to clean column names 
library(psych)   # for the describe function

library("stringr") # to add leading zeros
library(naniar) # to check missing values
library(simputation) # to replaces NAs
```

# 1. Exploratory Data Analysis

## 1.1 Import Data

```{r import data, include=FALSE}
data_death      <- read_csv("Data/death.csv")
data_health_ins <- read_csv("Data/healthinsurance.csv")
data_incidence  <- read_csv("Data/incidence.csv")
data_income     <- read_csv("Data/income.csv")
data_population <- read_csv("Data/population.csv")
data_poverty    <- read_csv("Data/poverty.csv")
```

## 1.2 Clean variable names

```{r naming convention of header}
data_death_clean      <- clean_names(data_death)
data_health_ins_clean <- clean_names(data_health_ins)
data_incidence_clean  <- clean_names(data_incidence)
data_income_clean     <- clean_names(data_income)
data_population_clean <- clean_names(data_population)
data_poverty_clean    <- clean_names(data_poverty)

names(data_death_clean)
names(data_health_ins_clean)
names(data_incidence_clean)
names(data_income_clean)       
names(data_population_clean)  
names(data_poverty_clean)

```

## 1.3 Data Exploration

```{r view data}
# Overall checks
head(data_death_clean) # "age_adjusted_death_rate" and “average_deaths_per_year” are character
head(data_health_ins_clean) 
head(data_incidence_clean) # "age_adjusted_incidence_rate_cases_per_100_000" and “average_annual_count” are character
head(data_income_clean)
head(data_population_clean)
head(data_poverty_clean)

summary(data_death_clean) 
summary(data_health_ins_clean) 
summary(data_incidence_clean)
summary(data_income_clean)
summary(data_population_clean)
summary(data_poverty_clean)
```

### 1.3.1 Check duplicates

```{r check duplicates}
# Check duplicates
data_death_clean %>% mutate(dup = duplicated(data_death_clean)) %>% filter(dup == TRUE)
data_health_ins_clean %>% mutate(dup = duplicated(data_health_ins_clean)) %>% filter(dup == TRUE)
data_incidence_clean %>% mutate(dup = duplicated(data_incidence_clean)) %>% filter(dup == TRUE)
data_income_clean %>% mutate(dup = duplicated(data_income_clean)) %>% filter(dup == TRUE)
data_population_clean %>% mutate(dup = duplicated(data_population_clean)) %>% filter(dup == TRUE)
data_poverty_clean %>% mutate(dup = duplicated(data_poverty_clean)) %>% filter(dup == TRUE)
  # No duplicates for all datasets
```

### 1.3.2 Convert Data Type

```{r data type conversion}
# [Death] Convert the data type from character to numeric
data_death_clean2 <- data_death_clean %>%
  mutate(age_adjusted_death_rate=as.double(age_adjusted_death_rate)) %>%
  mutate(average_deaths_per_year=as.double(average_deaths_per_year))

miss_var_summary(data_death_clean)
miss_var_summary(data_death_clean2)
  # 331 suppressed values "*" are automatically converted to NA by coercion


# [Incidence] Convert the data type from character to numeric
data_incidence_clean2 <- data_incidence_clean %>%
  mutate(age_adjusted_incidence_rate_cases_per_100_000=as.double(age_adjusted_incidence_rate_cases_per_100_000)) %>%
  mutate(average_annual_count=as.double(average_annual_count))

miss_var_summary(data_incidence_clean)
miss_var_summary(data_incidence_clean2)
  # 442 suppressed values "*" are automatically converted to NA by coercion

# [Income] Convert the data type from character to numeric
summary(data_income_clean)

data_income_clean$income_b_001 <- as.double(data_income_clean$income_b_001)
data_income_clean$income_c_001 <- as.double(data_income_clean$income_c_001)
data_income_clean$income_d_001 <- as.double(data_income_clean$income_d_001)
data_income_clean$income_e_001 <- as.double(data_income_clean$income_e_001)
data_income_clean$income_f_001 <- as.double(data_income_clean$income_f_001)
data_income_clean$income_g_001 <- as.double(data_income_clean$income_g_001)
data_income_clean$income_h_001 <- as.double(data_income_clean$income_h_001)
data_income_clean$income_i_001 <- as.double(data_income_clean$income_i_001)

data_income_clean

```

### 1.3.3 Reshaping Data into Tidy Form 

```{r reshaping}
# Separate state names from county
data_death_state <- data_death_clean2 %>% separate(county, c("county_name","state_name"), ", ")
  # Missing pieces are autimatically filled with `NA` in 2 rows, needs to check 

data_death_state %>% filter(is.na(county_name)) # no "NA"
data_death_state %>% filter(is.na(state_name))  # one is United States, the other is District of Columbia (State) (DC)

data_death_state1 <- data_death_state %>% mutate(state_name  = ifelse(county_name == "District of Columbia (State)", "DC", state_name))

data_death_state2 <- data_death_state1 %>% mutate(state_name  = ifelse(county_name == "United States", "US", state_name))

data_death_state2 %>% filter(is.na(state_name)) # no more missing values in state_name


# Check the number of the distinct states
n_distinct(data_death_state2$state_name) # Unique number of states is 54. Based on the domain knowledge, the United States is made up of a total of 50 states, plus the District of Columbia.

# Check the list of states
unique(data_death_state2$state_name) # "Arizona<sup>3</sup>" and "Alaska<sup>3</sup>" appear to be errors

data_death_state3 <- data_death_state2 %>% mutate(state_name = ifelse(state_name == "Alaska<sup>3</sup>", "Alaska", state_name))

data_death_state4 <- data_death_state3 %>% mutate(state_name = ifelse(state_name == "Arizona<sup>3</sup>", "Arizona", state_name))

# Check the number of the distinct states again
n_distinct(data_death_state4$state_name) # 52 = 50 states + 1 federal district + US as a whole
unique(data_death_state4$state_name) # looks alright

```

### 1.3.4 Internal Checks

```{r Nevada}
data_death_state4 %>% filter(state_name == "Nevada")
  # There are still 12 valid Nevada entries.
  # [Uncertainty] According to Sam, Nevada data is not available. But some Nevada data are actually valid in the death datasets. Include them for further analysis at the moment, but will ask Sam for clarification.


data_incidence_clean2 %>% filter(grepl('Nevada', county)) # Nevada data is not available

```

```{r health insurance}
# Check if Non-institutionalized Population (hi_001) = Non-institutionalized Population_male (hi_002) + Non-institutionalized Population female (hi_030)
data_health_ins_clean %>% 
  mutate(check = hi_001 - hi_002 - hi_030) %>% 
  group_by(state) %>% 
  summarise(sum(check)) 
  # all zero, passed the check
```


```{r poverty}
# Check if:
# 1) below poverty level population (poverty_002) = below poverty level male (poverty_003) + below poverty level female (poverty_017)
data_poverty_clean %>% 
  mutate(check = poverty_002 - poverty_003 - poverty_017) %>% 
  group_by(state) %>% 
  summarise(sum(check))
  # all zero, passed the check

# 2) above poverty level population (poverty_031) = above poverty level male (poverty_032) + above poverty level female (poverty_046)
data_poverty_clean %>% 
  mutate(check = poverty_031 - poverty_032 - poverty_046) %>% 
  group_by(state) %>% 
  summarise(sum(check))
  # all zero, passed the check

# 3) Population For Whom Poverty Status Is Determined (poverty_001) = below poverty level population (poverty_002) + above poverty level population (poverty_031)
data_poverty_clean %>% 
  mutate(check = poverty_001 - poverty_002 - poverty_031) %>% 
  group_by(state) %>% 
  summarise(sum(check))
  # all zero, passed the check

```

```{r population}
# Check the total population at mid-year 2015 on a national level.
sum(data_population_clean$popestimate2015)/10**6 # 642 million

# [Uncertainty] Based on the domain knowledge, the population of the United States should be around 320 million. It seems the number in the population dataset was doubled.

# This can be verified by the death dataset
data_death_state4 %>% 
  mutate(population = average_deaths_per_year / (age_adjusted_death_rate/100000)) %>% 
  filter(state_name == "US") %>% 
  pull(population)/10**6
  # 329 million

# Reduce the entire population data by half to make it more consistent with the real world.
data_population_clean_half <-  data_population_clean %>% mutate(popestimate2015 = popestimate2015/2)

sum(data_population_clean_half$popestimate2015)/10**6 # 321 million

```

## 1.4 Manipulate and Cleanse the Data

### 1.4.1 Clean FIPS

```{r FIPS}
# Make FIPS a 5-digit code 
# For death and incidence data, most of the FIPS codes are 5-digits but if they are 4-digits, you will need to add a 0 in front. 
data_death_clean_fips <- data_death_state4 %>% 
  mutate(fips_clean = str_pad(data_death_state4$fips, width = 5, pad = "0"))

data_incidence_clean_fips <- data_incidence_clean2 %>% 
  mutate(fips_clean = str_pad(data_incidence_clean2$fips, width = 5, pad = "0"))

# For poverty, health insurance, income and population data, you will need to combine State FIPS and County FIPS to get the 5-digit code.
data_health_ins_clean_fips <- data_health_ins_clean %>% 
  mutate(state_fips_clean  = str_pad(data_health_ins_clean$state_fips, width = 2, pad = "0")) %>% 
  mutate(county_fips_clean = str_pad(data_health_ins_clean$county_fips, width = 3, pad = "0")) %>% 
  mutate(fips_clean = paste(state_fips_clean, county_fips_clean, sep=""))

data_income_clean_fips <- data_income_clean %>% 
  mutate(state_fips_clean  = str_pad(data_income_clean$state_fips, width = 2, pad = "0")) %>% 
  mutate(county_fips_clean = str_pad(data_income_clean$county_fips, width = 3, pad = "0")) %>% 
  mutate(fips_clean = paste(state_fips_clean, county_fips_clean, sep=""))

data_population_clean_fips <- data_population_clean_half %>% 
  mutate(state_fips_clean  = str_pad(data_population_clean_half$state, width = 2, pad = "0")) %>% 
  mutate(county_fips_clean = str_pad(data_population_clean_half$county, width = 3, pad = "0")) %>% 
  mutate(fips_clean = paste(state_fips_clean, county_fips_clean, sep=""))

data_poverty_clean_fips <- data_poverty_clean %>% 
  mutate(state_fips_clean  = str_pad(data_poverty_clean$state_fips, width = 2, pad = "0")) %>% 
  mutate(county_fips_clean = str_pad(data_poverty_clean$county_fips, width = 3, pad = "0")) %>% 
  mutate(fips_clean = paste(state_fips_clean, county_fips_clean, sep=""))

```

### 1.4.2 Check Duplicate FIPS
distinct() shows you which rows of the dataframe are distinct i.e. removes the duplicate rows.
To find out the duplicates, you can use the function duplicated().

```{r check FIPS}


dim(data_death_clean_fips)[1] == length(unique(data_death_clean_fips$fips_clean)) # No duplicates
dim(data_incidence_clean_fips)[1] == length(unique(data_incidence_clean_fips$fips_clean)) # No duplicates
dim(data_health_ins_clean_fips)[1] == length(unique(data_health_ins_clean_fips$fips_clean)) # No duplicates
dim(data_income_clean_fips)[1] == length(unique(data_income_clean_fips$fips_clean)) # No duplicates
dim(data_population_clean_fips)[1] == length(unique(data_population_clean_fips$fips_clean)) # No duplicates
dim(data_poverty_clean_fips)[1] == length(unique(data_poverty_clean_fips$fips_clean)) # No duplicates

# # Alternative 1
# data_death_clean_fips %>% summarise(n_distinct(fips_clean))
# 
# # Alternative 2
# dup = duplicated(data_death_clean_fips$fips_clean) #returns logical vector
# data_death_clean_fips$fips_clean[dup] #to check any duplicates in key

```

### 1.4.3 Expert Opinion

```{r expert opinion on incidence trend}
# For Incidence dataset, expert opinion suggests suppressed cells of * for Recent Trend is likely to be stable.
table(data_incidence_clean_fips$recent_trend) # observe 422 *

data_incidence_clean_fips_expert <- data_incidence_clean_fips %>% mutate(recent_trend, recent_trend = ifelse(recent_trend == "*", "stable", recent_trend))

table(data_incidence_clean_fips_expert$recent_trend) # 422 more "stable" entries

# Apply Dummy Encoding for categorical variable "recent_trend"
data_incidence_clean_fips_expert_encoding <- data_incidence_clean_fips_expert %>%
  mutate(trend_falling = ifelse(recent_trend == "falling", 1, 0)) %>%
  mutate(trend_rising  = ifelse(recent_trend == "rising", 1, 0))

table(data_incidence_clean_fips_expert_encoding$trend_falling)
table(data_incidence_clean_fips_expert_encoding$trend_rising)

```
### 1.4.4 Imbalanced Data (to-do: maybe for data_all)


- The process of cleansing and manipulating the data often comes after you have understood the data and tried to look at patterns in the data through visualization.


rising is too small?
No, cuz it is not response variable

## 1.5 Visualise and Analyse Patterns in Data

### 1.5.1 Create State Abbreviations Column in Death Dataset

```{r add state abbr.}
data_death_clean_fips_with_state <- left_join(data_death_clean_fips, data_health_ins_clean_fips %>% select(state, fips_clean), by="fips_clean")

# Assign "US" to for the national level
data_death_clean_fips_with_state <- data_death_clean_fips_with_state %>% mutate(state = ifelse(state_name == "US", "US", state))

table(data_death_clean_fips_with_state$state_name)
n_distinct(data_death_clean_fips_with_state$state_name)

table(data_death_clean_fips_with_state$state)
n_distinct(data_death_clean_fips_with_state$state, na.rm = T)

```

### 1.5.2 Visualisation
- Communicate a data driven finding
- Useful if difficult to extract insights from tables of raw values

*See Week 4 Notes Page 7


```{r Visualisation: number of state}
# Check number of entries for each state
data_death_clean_fips_with_state %>% ggplot(aes(state, fill = state)) +
  geom_bar(show.legend = F) +
  theme_economist()

data_death_clean_fips_with_state %>% filter(is.na(state))
#   theme(axis.title.x=element_blank(),
#         axis.text.x=element_blank(),
#         axis.ticks.x=element_blank())
```


```{r Visualisation: stroke mortality rates}
# Check stroke mortality rates by state and see where the average of the nation (US) sits among other states
summary_death_data_all_state <- data_death_clean_fips_with_state %>% group_by(state) %>% summarize(death_rate = mean(age_adjusted_death_rate, na.rm=TRUE))

summary_death_data_us <- data_death_clean_fips_with_state %>% filter(state == "US")

ggplot() +
  geom_col(data = summary_death_data_all_state, aes(state, death_rate)) +
  geom_col(data = summary_death_data_us, aes(state, age_adjusted_death_rate, fill = state)) +
  theme(axis.title.x=element_blank(),
        # axis.text.x=element_blank(),
        axis.ticks.x=element_blank()) +
  theme_economist()

```

## 1.6 Create Final Dataset

### 1.6.1 Join Datasets

```{r join data step 1}
# Step 1: death + incidence
dim(data_death_clean_fips_with_state)
dim(data_incidence_clean_fips_expert_encoding)
names(data_incidence_clean_fips_expert_encoding)

# Remove columns that are already contained in the left-hand data
data_incidence_join <- data_incidence_clean_fips_expert_encoding %>% 
  select(c(3:8))

# Left Join - death / incidence
joined_data1 <- left_join(data_death_clean_fips_with_state, data_incidence_join, by="fips_clean")
joined_data1
names(joined_data1)
```

```{r join data step 2}
# Step 2: + health
dim(data_health_ins_clean_fips)
names(data_health_ins_clean_fips)

# Remove columns that are already contained in the left-hand data
data_health_ins_join <- data_health_ins_clean_fips %>% 
  select(c(5:61,64))

# Left Join - death / incidence / health
joined_data2 <- left_join(joined_data1, data_health_ins_join, by="fips_clean")
joined_data2
names(joined_data2)
```


```{r join data step 3}
# Step 3: + income
dim(data_income_clean_fips)
names(data_income_clean_fips)

# Remove columns that are already contained in the left-hand data
data_income_join <- data_income_clean_fips %>% 
  select(c(5:14,17))

# Left Join - death / incidence / health / income
joined_data3 <- left_join(joined_data2, data_income_join, by="fips_clean")
joined_data3
names(joined_data3)
```


```{r join data step 4}
# Step 4: + population
dim(data_population_clean_fips)
names(data_population_clean_fips)

# Remove columns that are already contained in the left-hand data
data_population_join <- data_population_clean_fips %>% 
  select(c(5,8))

# Left Join - death / incidence / health / income / population
joined_data4 <- left_join(joined_data3, data_population_join, by="fips_clean")
joined_data4
names(joined_data4)
```

```{r join data step 5}
# Step 5: + poverty
dim(data_poverty_clean_fips)
names(data_poverty_clean_fips)

# Remove columns that are already contained in the left-hand data
data_poverty_join <- data_poverty_clean_fips %>% 
  select(c(5:63,66))

# Left Join - death / incidence / health / income / population / poverty
joined_data_all <- left_join(joined_data4, data_poverty_join, by="fips_clean")

glimpse(joined_data_all)

# Check in EXCEL: 
# write_excel_csv(joined_data_all, "data_all.csv", col_names = TRUE)

```

### 1.6.2 Check Missing Values (To-do)

- Are those that have been suppressed to ensure confidentiality
missing at random: omit it
missing for a specific group: impute

gapminder_all %>% filter(!is.na(population)) %>%
summarise(mean_pop = mean(population), sd_pop = sd(population))

```{r missing values}
# To ensure all the suppressed values "*" are shown as "NA"
joined_data_all_with_NA <- joined_data_all %>% mutate(across(everything(), function(x){ifelse(x == "*" | x == ".", NA, x)}))

# Overview on missing values
miss_var_summary(joined_data_all_with_NA)  


# Response variable age_adjusted_death_rate: 331 rows have missing values. 
# Remove those rows.
joined_data_all_y <- joined_data_all_with_NA %>% filter(!is.na(age_adjusted_death_rate))
miss_var_summary(joined_data_all_y)


# Remove "US" entry as none of the social determinants datasets contain input for "US"
joined_data_all_y_no_us <- joined_data_all_y %>% filter(state != "US")
miss_var_summary(joined_data_all_y_no_us)


# Since only income_001 is one of the explanatory variables, missing values in other income variables can be ignored.
# Hence those variables are entirely removed.
drop_cols <- c(names(data_income_clean)[6:14])

joined_data_all_y_no_us_income <- joined_data_all_y_no_us %>% select(-one_of(drop_cols))
miss_var_summary(joined_data_all_y_no_us_income)


# Remove Nevada Data
joined_data_all_y_no_us_income_no_nevada <- joined_data_all_y_no_us_income %>% filter(state_name != "Nevada")
joined_data_all_y_no_us_income %>% filter(state_name == "Nevada")

miss_var_summary(joined_data_all_y_no_us_income)


# Check on incidence missing values
joined_data_all_y_no_us_income_no_nevada %>% filter(is.na(age_adjusted_incidence_rate_cases_per_100_000))
  # for these rows, "average_annual_count" is also missing or less than 5 

# Check on incidence missing values where both "age_adjusted_incidence_rate" and "average_annual_count" are missing
joined_data_all_y_no_us_income_no_nevada %>% group_by(state) %>% 
  filter(is.na(age_adjusted_incidence_rate_cases_per_100_000) & is.na(average_annual_count)) %>% 
  summarise(sum(age_adjusted_incidence_rate_cases_per_100_000)) # Zero for KS and MN, needs to check
   
joined_data_all_y_no_us_income_no_nevada %>% filter(state %in% c("KS", "MN")) # Incidence data is missing for KS and MN

# Remove observations where both "age_adjusted_incidence_rate" and "average_annual_count" are missing (i.e. KS and MN observations)
joined_data_all_y_no_us_income_no_nevada_incidence <- joined_data_all_y_no_us_income_no_nevada %>% filter(!is.na(average_annual_count))

miss_var_summary(joined_data_all_y_no_us_income_no_nevada_incidence)

# Replace remaining NAs in incidence rate with 0
joined_data_all_final <- joined_data_all_y_no_us_income_no_nevada_incidence %>%
  impute_const(age_adjusted_incidence_rate_cases_per_100_000~0)

miss_var_summary(joined_data_all_final) # no more NAs

n_distinct(joined_data_all_final$state_name) # only 48 States remain in the dataset.
# 51 - Nevada - Kansas - Minnesota = 48

```


### 1.6.3 Generate Explanatory Variables for the Preliminary Multiple Linear Regression Model

```{r total_below_poverty_level_per_capita}

# Total below poverty level per capita
joined_data_all_final <- joined_data_all_final %>% mutate(total_below_poverty_level_per_capita = poverty_002 / popestimate2015)

# Check min and max value
describe(joined_data_all_final$total_below_poverty_level_per_capita)

summary_below_poverty_level_per_capita_by_state <- joined_data_all_final %>% 
  group_by(state) %>% 
  summarise(below_poverty_level_per_capita = sum(poverty_002) / sum(popestimate2015) ) 

ggplot_poverty_level <- summary_below_poverty_level_per_capita_by_state %>% 
  ggplot(aes(state, below_poverty_level_per_capita)) +
  geom_col(show.legend = F) +
  theme_economist()


ggplot_poverty_level + labs(title = "Total below poverty line per capita",
                            subtitle = " i.e. total population below poverty level / total population")
```


```{r total_without_health_ins_per_capita}

# Total without health insurance
joined_data_all_final <- joined_data_all_final %>% 
  mutate(total_without_health_ins = 
           hi_005 + hi_008 + hi_011 + hi_014 + hi_017 + hi_020 + hi_023 + hi_026 + hi_029 +
           hi_033 + hi_036 + hi_039 + hi_042 + hi_045 + hi_048 + hi_051 + hi_054 + hi_057)

# Total without health insurance per capita
joined_data_all_final <- joined_data_all_final %>% mutate(total_without_health_ins_per_capita = total_without_health_ins / popestimate2015)

# Check min, max
describe(joined_data_all_final$total_without_health_ins_per_capita)

  # joined_data_all %>% filter(total_without_health_ins_per_capita>=1) %>% 
  #   select(fips_clean, state, total_without_health_ins, total_without_health_ins_per_capita, popestimate2015)
  # 
  # joined_data_all %>% filter(is.na(state)) %>% 
  #   select(fips_clean, state, total_without_health_ins, total_without_health_ins_per_capita, popestimate2015)

summary_without_health_ins_per_capita_by_state <- joined_data_all_final %>% 
  group_by(state) %>% 
  summarise(without_health_ins_per_capita = sum(total_without_health_ins) / sum(popestimate2015) ) 

ggplot_without_health_ins <- summary_without_health_ins_per_capita_by_state %>% 
  ggplot(aes(state, without_health_ins_per_capita)) +
  geom_col(show.legend = F) +
  theme_economist()

ggplot_without_health_ins + labs(title = "Total without health insurance per capita ",
                            subtitle = " i.e. sum of the population without health insurance coverage for each age group / total population")
```


```{r median_income}

# Median income - income_001
# Check median income by State (assume the average income is similar to the median income)
summary_median_income_by_state <- joined_data_all_final %>% 
  group_by(state) %>% 
  summarise(median_income_by_state = sum(income_001*popestimate2015) / sum(popestimate2015) ) 

ggplot_income <- summary_median_income_by_state %>% 
  ggplot(aes(state, median_income_by_state)) +
  geom_col(show.legend = F) +
  theme_economist()

ggplot_income + labs(title = "Median income fot the whole population",
                  subtitle = "i.e. income_001")
```


```{r incidence_rate}
# Incidence rate (Age-Adjusted Incidence Rate - cases per 100,000)
# [Uncertainty: only for aged 75 and above?]
# Check incidence rate by state
summary_incidence_by_state <- joined_data_all_final %>%
  group_by(state) %>%
  summarise(incidence_rate_per_100000 = sum(age_adjusted_incidence_rate_cases_per_100_000 * popestimate2015) / sum(popestimate2015) )

# # Zero for KS and MN, check
# joined_data_all_final %>% filter(state %in% c("KS", "MN")) %>% describe() # Incidence data is missing for KS and MN
# 
# # Remove Ks and MN rows
# joined_data_all_final <- joined_data_all_final %>% filter(!state %in% c("KS", "MN"))

ggplot_incidence <- summary_incidence_by_state %>%
  ggplot(aes(state, incidence_rate_per_100000)) +
  geom_col(show.legend = F) +
  theme_economist()

ggplot_incidence + labs(title = "Incidence rate",
                     subtitle = "i.e. age_adjusted_incidence_rate_cases_per_100_000")
```

```{r incidence_trend & population}
ggplot_pop <- joined_data_all_final %>%
  ggplot(aes(state, popestimate2015, fill = recent_trend)) +
  geom_col() +
  theme_economist() +
  scale_y_continuous(labels = function(x) format(x, big.mark = ",", scientific = FALSE))

ggplot_pop + labs(x = "State", y = "Population", title = "Population at year of 2015")

```


```{r final dataset}
# The final dataset for modelling purpose
joined_data_all_final_LRM <- joined_data_all_final %>% select(county_name, 
                                                       state_name, 
                                                       state,
                                                       fips_clean,
                                                       age_adjusted_death_rate,
                                                       total_below_poverty_level_per_capita,
                                                       total_without_health_ins_per_capita,
                                                       income_001,
                                                       age_adjusted_incidence_rate_cases_per_100_000,
                                                       trend_falling,
                                                       trend_rising,
                                                       popestimate2015) %>% rename(
                                                         stroke_mort = "age_adjusted_death_rate",
                                                         below_poverty = "total_below_poverty_level_per_capita",
                                                         no_health_ins = "total_without_health_ins_per_capita",
                                                         median_income = "income_001",
                                                         incidence = "age_adjusted_incidence_rate_cases_per_100_000",
                                                         incidence_falling = "trend_falling",
                                                         incidence_rising = "trend_rising",
                                                         population = "popestimate2015"
                                                          )

corrplot(cor(joined_data_all_final_LRM[, 5:12], use="pairwise.complete.obs"))

```

                        





#=======================================================#

# The advantage of faceting compared to grid.arrange() below is that it keeps the axes fixed across all plots, easing comparisons between plots.


## 1.3 Assess Data Quality

### 1.3.1 Summarise Data

### 1.3.2 gg plot

### 1.3.3 Visualise and Analyse Patterns in Data
```{r}


# test
# ggplot(data_death_clean, aes(average_deaths_per_year, age_adjusted_death_rate, group = state_name)) +
# geom_line() +
# facet_wrap(. ~ state_name)

# state_death <- data_death_clean_state %>% ggplot(aes(state_name, death_rate, fill = state_name)) +
#   geom_col(show.legend = F) + 
#   theme(axis.title.x=element_blank(),
#         axis.text.x=element_blank(),
#         axis.ticks.x=element_blank())
# 
# ggsave("state_death.jpg", state_death)

```







```{r}



#==========Example=========#
# exposuretotal <- summary_veh_brand %>% select(veh_brand, exposuretot)
# summary_veh_brand_area <- motor_data %>% group_by(veh_brand, area) %>% summarise(exposure=sum(exposure), claim_num = sum(claim_nb))
# 
# summary_veh_brand_area_total <- left_join(summary_veh_brand_area,summary_veh_brand, by="veh_brand") %>%
#   mutate(incr_freq = claim_num/exposuretot, rel_freq = incr_freq/frequency)
# 
# summary_veh_brand_area_total
# #write_excel_csv(summary_veh_brand_area_total, "Test_Vinc.csv", col_names = TRUE)
# 
# summary_veh_brand_area_total %>% ggplot(aes(veh_brand, rel_freq, fill=area)) +
#   geom_bar(stat = 'identity') #stat identity allows you to make to a y value for bar
#==========================#


# data_all %>% ggplot(aes(state, age_adjusted_death_rate), ) + 
#   geom_boxplot()
#   theme(legend.position="none" #不需要图例
#         # axis.text.x=element_text(colour="black",family="Times",size=14), #设置x轴刻度标签的字体属性
#         # axis.text.y=element_text(family="Times",size=14,face="plain"), #设置x轴刻度标签的字体属性
#         # axis.title.y=element_text(family="Times",size = 14,face="plain"), #设置y轴的标题的字体属性
#         # axis.title.x=element_text(family="Times",size = 14,face="plain"), #设置x轴的标题的字体属性
#         # plot.title = element_text(family="Times",size=15,face="bold",hjust = 0.5), #设置总标题的字体属性
#         # panel.grid.major = element_blank(), #不显示网格线
#         # panel.grid.minor = element_blank()
#         )
#   + scale_y_continuous(breaks = NULL)

```

## 1.X Refine questions/generate new questions (optional)

EDA should not be viewed as just conducting the above framework as a
series of ordered steps. This is far too simplistic as EDA typically
involves multiple rounds of each step. For example, visualisations could
give you new ideas for summaries you would be interested in and perhaps
patterns you want to analyse, which could lead to more manipulations to
the data and visualisations.

### Internal Checks

# Correlation


Exploratory data analysis

Objectives: •Suggest hypotheses •Assess assumptions made •Support
selection of appropriate models •Provide basis for further data
collection

FrameworK: 1. Assess the data quality

# 提取各个模型的诊断信息

by_country %\>% summarise(glance(model))




#================ NA in income_001 for one TX country
# a_test <- joined_data_all_final %>% 
#   mutate(income_pop = income_001*popestimate2015)
#   
#   
# a_test %>% group_by(state) %>% 
#   summarise(median_income_by_state = sum(income_pop) / sum(popestimate2015) ) %>% 
#   ggplot(aes(state, median_income_by_state, fill = state), na.rm = T) +
#   geom_col(show.legend = F) +
#   theme_economist()  
# 
# a_test %>% filter(state == "TX") %>% 
#     select(fips_clean, state, income_001, popestimate2015, income_pop)
# 
# a_test %>% filter(is.na(income_001))
